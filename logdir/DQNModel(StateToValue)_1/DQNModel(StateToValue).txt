Model: DQNModel(StateToValue) 

Environment Variables 
depth_of_code = 5
rows = 3
cols = 2
max_swaps_per_time_step = -1

Model Variables 
learning_starts = 20000
verbose = 1
exploration_fraction = 0.5
exploration_initial_eps = 1
exploration_final_eps = 0.05
batch_size = 512
learning_rate = 0.001
target_update_interval = 20000
tau = 0.3
gamma = 0.4
train_freq = 4

Training Variables 
total_timesteps = 100000
log_interval = 4

Evaluation 
n_eval_episodes = 20

Results 
np.mean(rewards) = -29.15
mean_reward = -5.15
